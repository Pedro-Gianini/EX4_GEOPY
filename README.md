## Solução dos exercícios da TERCEIRA aula do curso GeoPY
## OSM, análise de vizinhança e reclassificação de dados

Bibliotecas usadas: gdal-bin python-gdal python3-gdal ; python3-rtree ; geopandas==0.10.0 ; descartes ; os ; pandas ; matplotlib.pyplot ; re ; contextily ; mapclassify

Funções aprendidas: camin=''; os.chdir(''); tight_layout() ; re.findall ; .rename ; .dissolve('') ; .set_index ; .groupby ; .listdir() ; .startswith('') ; 

Conteúdos abordados/ explicação dos exercícios : 
Primeiramente, são instaladas as bibliotecas e é feita a montagem do Google Drive. Para ler os arquivos, importamos o pacote "os" e definimos uma lista vazia, na qual adicionamos todos os arquivos que começam com "TravelTimes_to" por meio de um loop de leitura dos arquivos da pasta. A pasta que armazena os arquivos é a mesma em que estamos, pois mudamos o diretório usando a função os.chdir('').
Em seguida, lemos o arquivo CSV de um dos endereços (shoppings) e selecionamos as colunas de interesse ('pt_r_tt', 'car_r_t', 'from_id', 'to_id'). Para medir o tempo de viagem de transporte público e carro, lemos os que possuem o tempo de deslocamento através de cada coordenada da lista e adicionamos as colunas 'from_id' e 'YKR_ID' na tabela do shopping analisado. Filtramos as linhas que não possuem dados.
Depois disso, usamos a biblioteca mapclassify juntamente com matplotlib.pyplot para plotar 2 mapas: um que contém o tempo de deslocamento de transporte público e outro que contém o tempo de deslocamento de carro.

No segundo exercício, é solicitada a área de influência de cada shopping. Para isso, iniciamos importando a biblioteca "re" para formatar e padronizar os textos. Depois, é feito um loop para indicar todos os tempos de viagem. Para isso, copiamos o grid do polígono já usado anteriormente e criamos duas listas vazias para representar o nome (labels) das colunas de carro e transporte público. Em seguida, é criado um loop para ler todos os arquivos, lendo o arquivo CSV e considerando apenas os dados maiores que zero. Depois, são extraídos os nomes dos shoppings para que esses nomes sejam adicionados, correlacionando o tempo de deslocamento e o transporte usado para cada shopping. Essas colunas são renomeadas para facilitar a visualização. Depois, essas colunas são adicionadas às listas vazias criadas no início (pe_labs=[] e car_labs=[]). Em seguida, é feita a seleção das colunas [car_lab, pe_lab, 'from_id'], as quais são selecionadas para fazer um "table join" com os tempos de viagem e o grid. Usamos "del" para evitar colunas duplicadas. Depois, precisamos descobrir o menor tempo de viagem para carro e o shopping que está nesse alcance. Para isso, criamos duas listas vazias, "tt_all['influencia']" e "tt_all['min_car']", sendo que a primeira coluna chamada "min_car" será utilizada para armazenar o tempo mínimo de viagem de carro e a segunda coluna chamada "influencia" será utilizada para armazenar o nome do shopping que está ao alcance nesse tempo mínimo de viagem.
Em seguida, um loop "for" é utilizado para iterar sobre todas as linhas do DataFrame "tt_all". Para cada linha, o tempo mínimo de viagem de carro é calculado usando a função "min()", que retorna o menor valor de uma lista. A função "loc" é utilizada para atribuir esse valor à coluna "min_car" na linha correspondente. Depois, um novo DataFrame chamado "df" é criado a partir dos valores da linha atual. A primeira coluna desse DataFrame é renomeada para "tempo". Em seguida, o índice da linha que contém o tempo mínimo de viagem de carro é selecionado usando a função "idxmin()". O nome do shopping correspondente é extraído do índice selecionado usando a função "split()" e atribuído à coluna "influencia" na linha correspondente do DataFrame "tt_all". As últimas duas partes do código são para visualizar os resultados. A coluna "min_car" é plotada usando a função "plot()" da biblioteca "geopandas" e um classificador é especificado usando a opção "scheme". Já para a coluna "influencia", não é necessário definir nenhum classificador, uma vez que os valores são qualitativos.

No terceiro e último exercício, começamos pela etapa a, que consiste em ler os dados de população. É utilizado o módulo geopandas (gpd) e a função read_file() para ler o arquivo shapefile que contém as informações de população. Essas informações são armazenadas no objeto pop20. Na etapa b, é utilizada a função dissolve() para agregar os polígonos que pertencem à mesma área de influência dos shoppings, criando assim polígonos únicos de área de influência para cada shopping. O resultado é armazenado no objeto area_influ. Na etapa c, é realizado um spatial join (junção espacial) entre as áreas de influência e os dados de população. Antes disso, é verificado se os dados estão no mesmo sistema de coordenadas e, caso não estejam, os dados de população são reprojetados para o mesmo sistema de coordenadas das áreas de influência. O resultado do spatial join é armazenado no objeto pop_join. Na etapa d, é realizada a soma da população na área de cada shopping, agrupando os dados resultantes do spatial join por área de influência. É criada uma nova coluna para guardar os nomes das áreas de influência, que foram transformados em índice, uma nova coluna com valores de índice e, em seguida, a nova coluna é definida como índice do geodataframe. O resultado é armazenado no objeto pop. Na etapa e, é realizado um table join (junção de tabelas) entre os dados do agrupamento em d e as geometrias das áreas de influência. É utilizada a função merge() para combinar os dados de população total por área de influência com as geometrias das áreas de influência dos shoppings. O resultado é armazenado no objeto pop_shop. Por fim, na etapa f, é criado um mapa com a biblioteca contextily, adicionando um mapa base de fundo e visualizando o resultado com a utilização de um classificador e um esquema de cores.
